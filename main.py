import os
import json
from datetime import datetime
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
import streamlit as st

# é…ç½®é¡µé¢è®¾ç½®ï¼Œé€‚åˆiframeåµŒå…¥
st.set_page_config(
    page_title="Qwen Chat",
    page_icon="ğŸ¤–",
    layout="centered",  # ç´§å‡‘å¸ƒå±€æ›´é€‚åˆiframe
    initial_sidebar_state="collapsed"  # ä¾§è¾¹æ é»˜è®¤æŠ˜å 
)

# ç§»é™¤é¡µé¢åº•éƒ¨çš„"Made with Streamlit"å’Œæ±‰å ¡èœå•
hide_streamlit_style = """
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# é…ç½®APIå¯†é’¥
os.environ["DASHSCOPE_API_KEY"] = "sk-15292fd22b02419db281e42552c0e453"

# åˆå§‹åŒ–æ¨¡å‹
llm = ChatTongyi(model_name="qwen-plus")

# å®šä¹‰æç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a friendly chatbot. Please respond in a natural and concise manner."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}"),
])

# æ„å»ºå¯¹è¯é“¾
chain = prompt | llm
chain_with_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: ChatMessageHistory(),
    input_messages_key="input",
    history_messages_key="history",
)

# æ ‡é¢˜ä½¿ç”¨è¾ƒå°çš„å­—ä½“ï¼Œé€‚åˆiframeç©ºé—´
st.header("AI Chat Interface")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºèŠå¤©å†å²
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
if user_input := st.chat_input("Type your message..."):
    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # ç”ŸæˆAIå›å¤
    with st.chat_message("assistant"):
        response = chain_with_history.invoke(
            {"input": user_input},
            config={"configurable": {"session_id": "default"}}
        )
        st.markdown(response.content)

    # ä¿å­˜å›å¤åˆ°å†å²
    st.session_state.messages.append({"role": "assistant", "content": response.content})

    # å‘é€æ¶ˆæ¯ç»™çˆ¶é¡µé¢ï¼ˆiframeå®¹å™¨ï¼‰
    message = {
        "type": "chat-update",
        "messages": st.session_state.messages
    }
    js_code = f"""
    <script>
        window.parent.postMessage({json.dumps(message)}, "*");
    </script>
    """
    st.markdown(js_code, unsafe_allow_html=True)

# ç›‘å¬æ¥è‡ªçˆ¶é¡µé¢çš„æ¶ˆæ¯
st.markdown("""
<script>
    // ç›‘å¬çˆ¶é¡µé¢æ¶ˆæ¯
    window.addEventListener('message', function(event) {
        // å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯
        if (event.data.type === 'clear-chat') {
            // æ¸…ç©ºèŠå¤©å†å²çš„é€»è¾‘
            window.parent.postMessage({type: 'chat-cleared'}, '*');
        }
    });
</script>
""", unsafe_allow_html=True)
